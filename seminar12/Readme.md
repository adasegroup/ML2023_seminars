* Attention seminar (part 1) without solutions - https://colab.research.google.com/github/adasegroup/ML2023_seminars/blob/master/seminar12/attention_seminar_part1/attention_seminar_with_TODO.ipynb
* Attention seminar (part 1) with solutions - https://colab.research.google.com/github/adasegroup/ML2023_seminars/blob/master/seminar12/attention_seminar_part1/attention_seminar.ipynb
* Transformer model seminar (part 2) - https://colab.research.google.com/github/adasegroup/ML2023_seminars/blob/master/seminar12/attention_seminar_part2/Attention_is_All_You_Need.ipynb
